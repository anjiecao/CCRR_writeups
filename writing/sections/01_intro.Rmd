Cross-cultural differences are a striking part of the broader landscape of human variation. Differences in values and behavior across cultures are obvious to even a casual observer, and researchers have attempted to quantify these differences via a wide range of measures. Comparisons between the United States and China -- often as exemplars of Western and East Asian cultures -- have been especially well-researched, with differences attested in a wide range of cognitive domains, including visual attention [@ji2000culture; @chua2005cultural; @waxman2016early], executive function [@tan2020chinese; @sabbagh2006development], language learning [@chan2011english;@tardif1996nouns; @chan2011english; @waxman2016early], relational reasoning [@carstensen2019context; @richland2010young; @cheng2020development; @su2020analogical], similarity judgments [@ji2004culture], values [@ji2001culture; @spencer2007culture; @kwan1997pancultural], preferences [@liang2012effect; @diyanni2015role; @corriveau2017cultural] and self-concepts [@spencer2009cultural; @spencer2009dialectical]. As a result, the US and China are increasingly treated as cultural poles in efforts to measure cultural differences [@muthukrishna2020beyond] and to correct for the pervasive bias in psychology research toward US and European samples [@henrich2010weirdest; @arnett2016neglected; @nielsen2017persistent].

Despite a long empirical tradition of comparisons between these two cultures and an abundance of psychological accounts for observed differences, estimates of differences are difficult to compare quantitatively because of the varying samples, measures, and methods used in different reports. Further, many of the most prominent reports of cross-cultural differences predate the field-wide discussion of methodological issues in psychology research during the past 10 years [@open2015estimating]. For example, much research in this tradition has been exploratory and hence has not followed current guidance regarding limiting analytic flexibility in order to decrease false positives [@simmons2011]. Given the importance of claims about specific cross-cultural differences for constructing theories of culture more broadly [e.g., @markus1992and;@markus2010cultures], replication of many empirical findings is likely warranted. 

Some empirical evidence points to issues in the robustness of cross-cultural measurements.  Typically, measures used in this literature are not standardized and do not have published evidence about reliability and validity [@flake2020measurement]. The few extant direct comparisons between measures of cultural difference suggest that theoretically related tasks, such as implicit and explicit measures of the same construct, might not cohere [e.g., @kitayama2009cultural]. Further, in a study with twenty cross-cultural measures used within a single US sample, @na2010cultural found a lack of coherence between tasks measuring social orientation and cognitive style, observing only 8 significant correlations between tasks across 90 statistical tests.^[These authors interpreted their findings as imply the measures are orthogonal -- indexing different constructs -- and concluded that group-level differences between cultures are unlikely to relate to within-group individual differences. However an alternative possibility is that the reliabilities of many individual tasks are low, a feature which would ensure low correlations between them.] Finally, more recent work failed to replicate cultural differences on several related measures [@zhou2008perceiving; @mercier2012use; @mercier2015easterners]. Thus, there is a need for exploration of the reliability of individual tasks as well as the intercorrelations between them.

Our goal in the current study was to replicate a set of cross-cultural measures that had previously been used in comparisons of East Asian and Western cultures (most often comparisons between US and either Chinese or Japanese participants). We made the decision to pursue the strategy of gathering relatively large and heterogeneous convenience samples using online recruitment, rather than recruiting smaller, more matched samples using in-lab recruitment. Our reasoning was that the larger samples that we could access using online recruitment would allow us to conduct highly-powered statistical tests, allowing us to either reject or accept the null hypothesis of no cultural difference between measures. Further, larger samples would afford the analysis of individual and demographic differences within culture, a topic of considerable interest in this literature [e.g., @na2010cultural]. Finally, the development of browser-based online versions of prominent cross-cultural tasks would allow their inspection and reuse by other researchers, thus promoting a more cumulative approach to the measurement of cultural differences. 

The interpretation of any replication result is complex, given that disparate outcomes between an initial study and a replication can occur for many reasons -- including but not limited to differences in experimental methods, sample or population differences, and simple sampling variation in the outcomes [@zwaan2018making,@nosek2020replication, @machery2020replication]. Our strategy of pursuing online convenience samples limits the interpretation of our replication results: nearly all of the tasks we selected were previously administered in person, and the populations sampled in previous reports varied but were largely convenience samples of either college students or community members. More generally, our strategy of constructing a battery of replication studies and administering them uniformly means that specific decisions about sampling and administration are not matched with the original studies. Thus, our replication studies should be taken as an assessment of whether a set of previously-reported cross-cultural differences can be recovered in convenience populations recruited online, rather than as assessments of the veracity of the original findings. Nevertheless, we believe that the field of cross-cultural psychology can be advanced via the identification of tasks that yield cross-cultural differences robustly across a variety of samples and administration formats -- we hope our work contributes to this aim. We return to these interpretive issues in the General Discussion.

Our task selection process was initially shaped by an interest in relational reasoning and accounts explaining it with reference to cross-cultural differences in visual attention and social cognition [e.g., @kuwabara2012cross; @duffy2009development; @moriguchi2012cultural]. Additionally, in Experiment 1, we selected tasks that could potentially be administered to young children as well as adults, for use in future work addressing developmental questions about the relative time course of cross-cultural differences across the visual, social, and cognitive domains. We balanced four desiderata in our task selection, preferentially choosing tasks that (1) had been theoretically or empirically implicated in relational reasoning, (2) were associated with differential performance in US-China comparisons or related cultural contrasts (e.g., East Asian vs. Western cultures), (3) were relatively short, accessible tasks appropriate for web administration, and (4) were vision or social cognition accounts for relational reasoning. We further conducted an extensive set of pilot tests to ensure that participants understood instructions and that the tasks yielded interpretable data. 

In Experiment 2, we selected a second set of tasks to investigate based in part on the results of Experiment 1. In particular, we repeated a handful of tasks from Experiment 1, in some cases, varying task parameters. We then selected a further set of tasks that probed both cross-cultural differences in higher-level cognition (e.g., language and reasoning) and perception, again respecting the desideratum that the tasks should be relatively short and amenable to administration in a web browser. The final set of tasks included in each Experiment is listed in Table 1.

In addition to the goal of replicating individual tasks, our hope was that the relatively large dataset that we collected could be used to explore the structure of within- and across-cultural variation in cognition and perception more broadly. Towards this goal, we included a relatively extensive demographic questionnaire in both of our Experiments, with the aim of using these measures to explore variation within our samples. In the final section of the paper, we report a series of exploratory analyses. The first of these assess the reliability of individual tasks, aiming to gauge whether individual tasks are reliable enough from a psychometric point of view to support further individual differences analyses. We then report across-task correlations, aiming to discover covariation between tasks that might indicate that they load on the same construct. Finally, we turn to analyses of whether within-culture demographic variables predict variation in task performance. Overall, a number of tasks revealed acceptable levels of reliability, but tasks did not cluster together and we found relatively few demographic predictors of within-culture variation.

<!-- #\begin{landscape} -->

\begin{table}[H]
    \tiny
    \centering
    \caption{\label{tab:Table 1} Tasks included in each experiment and the final sample size after exclusion.}
    \resizebox{\textwidth}{\textheight}{%
    \begin{tabular}{l p{1.5in} p{1.5in} p{1.5in} p{.5in} p{.5in}} 
        \hline
        \bf{Experiment} & \bf{Task} & \bf{Relevant Citation} & \bf{Task Description} & \bf{CN} & \bf{US} \\
        \hline

        1 & Ambiguous Relational Match-To-Sample (RMTS) & Carstensen et al. (2019) & Infer whether an object or relation is causally relevant & N = 167  & N = 169\\

& Picture Free Description & Imada, Carlson, \& Ktakura (2013) & Describe pictures from memory after a brief study period & N = 167 & N = 169\\

& Ebbinghaus Illusion & Imada, Carlson, \& Itakura (2013) & Judge the size of circles in a context designed to bias size judgments & N = 167  & N = 169\\

& Horizon Collage & Senzaki, Masuda, \& Nand (2014) & Make an image by dragging and dropping stickers onto a display & N = 167  & N = 169\\

& Symbolic Self-Inflation (Family) & Kitayama et al. (2009) & Draw self and family members as circles & N = 141 & N = 110\\

& Uniqueness Preference & Kim \& Markus (1999) & Choose a sticker from five stickers, four of which are the same color & N = 167 & N = 169\\

& Child Causal Attribution & Seiver, Gopnik, \& Goodman (2013) & Watch short vignettes and explain the decisions of the characters & N = 167 & N = 169\\

& Raven's Progressive Matrices & Su (2020) & Use analogic reasoning to complete visually-presented patterns & N = 167 & N = 169\\
2 & Ambiguous Relational Match-To-Sample (RMTS) & Carstensen et al. (2019) & Infer whether an object or relation is causally relevant & N = 174 & N = 293\\

& Picture Free Description & Imada, Carlson, \& Itakura (2013) & Describe pictures from memory after a brief study period & N = 132 & N = 284\\

& Change Detection & Mausda \& Nisbett (2007) & Find differences in the foreground or background of two images & N = 160 & N = 253\\

& Symbolic Self-Inflation (Friends) & Kitayama et al. (2009) & Draw a sociogram with self and friends as nodes, relationships as edges & N = 158 & N = 252\\

& Adult Causal Attribution & Morris \& Peng (1994) & Read a crime story and explain the criminalâ€™s motivations & N = 114 & N = 293\\

& Taxonomic-Thematic Similariy & Ji, Zhang, \& Nisbett (2004) & Match items based on taxonomic or thematic similarity (e.g., cow: chicken / grass) & N =178 & N = 295\\

& Semantic Intuition & Li, Liu, Chalmers, \& Snedeker (2018) & Decide whether a story refers to a named character (whose actions are mischaracterized) or the person who performed the actions (but had a different name) & N = 181 & N = 298\\

& Raven's Progressive Matrices & Su (2020) & Use analogical reasoning to complete visually-presented patterns & N = 181 & N = 298\\
    \hline
    \end{tabular}}

\end{table}


We make all code and data from our experiments available for further data collection and analysis in hopes of promoting further cumulative work on measures and theories of cross-cultural variation. 



