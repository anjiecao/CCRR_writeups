


Experiment 2 was designed to follow up on Experiment 1 and further evaluate cross-cultural differences across a battery of tasks. Because several of our tasks in Experiment 1 yielded no evidence for cross-cultural differences, we replaced these with alternative tasks selected to address similar or related constructs. We replaced the Ebbinghaus Illusion with a measure of Change Detection that has been argued to index context sensitivity [@masuda2006culture]. We replaced the child-appropriate causal attribution task with a version designed for adults [@morris1994culture]. We also included two tasks measuring linguistic or semantic intuitions more broadly (Taxonomic/Thematic Similarity and Semantic Intuition), following up on the detection of cross-cultural differences in the Picture Free Description task. Although our goal in Experiment 2 was to evaluate a further set of tasks, we also included the Ambiguous cRMTS, Picture Free Description, and Raven’s Progressive Matrices tasks to replicate our results from Experiment 1, and we included a modified version of Symbolic Self-Inflation to address several issues with the earlier version of the task. 

In Experiment 2, we made use of crowd-sourcing services – rather than snowball sampling – as our participant recruitment channel. Each of these sampling strategies has strengths and weaknesses. The strength of snowball sampling (used in Experiment 1) is the ability to sample from comparable university/student populations, but crowd-sourcing services allow us to access convenience populations more easily and scale more flexibly There are also two additional rationales. First, in Experiment 1 our samples were quite young (due to seeding our sampling with university students through email and social media). A younger sample may be less enculturated because they are less experienced or more exposed to international media and influences, and thus less likely to show distinct cross-cultural differences. Second, we were concerned that being recruited by friends and family (as in a snowball sample) might prime interdependent thinking among our participants, leading to decreased cross-cultural differences. 

```{r}
d2_raw <- read_csv(here("data/01_merged_data/exp2/merged_data.csv"))
d2 <- read_csv(here("data/03_processed_data/exp2/tidy_main.csv"))
d2_attrition <- read_csv(here("data/03_processed_data/exp2/attrition_table.csv"))
```

```{r}
raw_n_subject <- d2_raw %>% 
  distinct(culture, subject) %>% 
  group_by(culture) %>% count()
```

## Methods

### Participants 

We recruited participants through online crowdsourcing websites. For the US, we used Prolific and applied the following screening criteria: a) US nationality, b) born in the US, and c) currently residing in the US. For China, we used Naodao (www.naodao.com), a platform designed for conducting online experiments in mainland China. Participants in US received \$12.25 in compensation and in China ¥35. 

We recruited `r filter(raw_n_subject, culture == "US")$n` participants from the U.S. and `r filter(raw_n_subject, culture == "CN")$n` participants from China. `r d2_attrition %>% filter(exclusion_type == "whole_participant") %>% count() %>% pull()` participants were excluded because they did not meet our demographic inclusion criteria^[
Demographic exclusions: we would exclude data from [CN/US] participants who reported living abroad for more than 2 years in regions with predominantly [European/Asian] populations (respectively); and [CN/US] participants who reported speaking or understanding [English/any Chinese language or dialect] with proficiency at or above 3 out of 10. If this led to 20% or more of participants being excluded from either test population (US/CN), we would drop this exclusion criterion for the relevant population and use exploratory regressions to examine how the factor relates to responding in our tasks.
]. Following our preregistration (available at https://osf.io/u7mzg), we applied a task-based exclusion procedure in which we excluded a participant's responses in a particular task if they a) showed a response bias for a single response button or value^[
If more than 90% of selections by a participant in a 2AFC task were a single response button (left/right in RMTS or top/bottom in taxonomic/thematic similarity), data from this participant in this task would be excluded. If 100% of selections by a participant in a scalar (e.g., Likert scale used in causal attribution or in the demographics section) or multiple choice task (e.g. Raven’s SPM) used a single response button/value, data from this participant in this task would be excluded.
], b) had missing data on more than 25% of trials^[
If no data/more than 25% missing/data not codeable/side bias/participant did not follow instructions for any one task, then we would exclude all data from that participant, across tasks. If this led to 20% or more of participants being excluded, we would not apply this exclusion criteria to all data from the participant -- only at the level of individual tasks.
], or c) failed to meet the inclusion criteria for that task as specified in the preregistration^[
Additional task and trial-level exclusions:   
(1) Change detection: trials where the participant incorrectly identified the change would not be analyzed (but will not be counted as missing data unless a response was not attempted).   
(2) Free description: trials where the response was not code-able would be discarded and considered missing data.   
(3) Causal attribution: none.   
(4) Symbolic self-inflation: data from participants who failed to draw exactly one “self” circle would be excluded, as well as data from participants who drew only a “self” circle.   
(5) Taxonomic/thematic similarity task: There were two unambiguous catch trials intermixed with regular trials in this task (e.g., Choose cat: cat, dog). If a participant missed either unambiguous catch trial, all triad data from that participant would be excluded.   
(6) Semantic intuition: Participants would be excluded for missing any of the 5 control questions.   
(7) Ambiguous RMTS: none.   
(8) Raven’s SPM: none.
]. 

Similar to Experiment 1, we collected demographic information from participants, including subjective socioeconomic status, the state or province the participant grew up in and the one they currently reside in, residential mobility, number of international experiences, education, and undergraduate area of study (STEM or non-STEM). We also administered scales to collect explicit measures of participants’ cultural identities and behaviors [@cleveland2007acculturaton; @cleveland2015intersection; @strizhakova2013green]. 

The sample size for each task after exclusions and the descriptive statistics for each demographic question are reported in Table 1.

### Procedure 

Similar to Experiment 1, participants completed eight tasks and a brief demographics questionnaire online. The experiment was administered in English for the US sample and in Mandarin Chinese for the Chinese sample, with the exception of the Adult Causal Attribution task. As in previous work, this task was administered in English, and only Chinese participants who self-identified as being able to read English participated in it. To control for the impact of order-related inattention, task order was randomized across participants with two exceptions: (1) the Free Description task always occurred before (not necessarily immediately) Change Detection (because Change Detection included a manipulation check that explicitly asked about focal objects, which could bias responding in Free Description), and (2) the two story-based tasks (Semantic Intuition and Adult Causal Attribution) always occurred together in a fixed order at the end of the study, with Semantic Intuition first and Adult Causal Attribution last. Adult Causal Attribution was always the last task (if run) because it was administered in English and we did not wish to prime CN participants with English stimuli before any of the other tasks, all of which were run in Mandarin.

### Measures 

#### Tasks from Experiment 1

We replicated three tasks from Experiment 1 using identical procedures: Ambiguous cRMTS, Picture Free Description, and Raven’s Standard Progressive Matrices.

#### Symbolic Self-Inflation 

Participants were asked to draw themselves and their friends as circles, as opposed to drawing themselves and their family members as circles in Experiment 1. They were also asked to draw lines between any two people who are friends, as in the original study by @kitayama2009cultural. They then labeled each circle to indicate the person it represents. We calculated a percent inflation score for each participant by dividing the diameter of the self circle by the average diameter of circles for others.

#### Adult Causal Attribution 

We speculated that the lack of cross-cultural differences in Causal Attribution in Experiment 1 might be due to the simplistic nature of our task, which was designed for use with young children. Therefore, in Experiment 2 we used a paradigm designed for adults, in which participants were asked to read a crime narrative from a news report that included substantial information on a criminal’s background and the events leading up to their crime, and then rate the relevance of various situational and personal factors [@morris1994culture]. In the original study, both Chinese participants and US participants read stories in English. We followed this procedure by selecting the subset of our Chinese participants who self-identified as comfortable reading short stories in English to participate. In the task, participants were told that they would read news stories and answer questions to help social scientists understand the factors that contribute to murders. Participants were randomly assigned to read one of two stories (Iowa shooting or Royal Oak shooting). After the stories, they were asked to write a short explanation for the murderer’s behaviors. Then, they rated a list of statements about causes of the murder on a 7-point Likert scale. The statements included items that describe personal and situational factors, and we measured endorsement of these two factor types. 

#### Change Detection 

@masuda2006culture found differences in attention allocation between Japanese and US participants in a change detection paradigm. They found that Japanese participants were significantly faster than US participants in identifying changes in the background of images. We followed their original procedure and used the same stimuli. In this task, participants were presented with 30 pairs of images. On each trial, two pictures would alternate on the screen, each presented for 560ms with a blank screen in between images for 80ms. The two pictures were almost identical with subtle differences, either in the focal object (e.g., a tractor in daylight with its lights on or off) or the background (e.g., a cloud with slightly different locations in the sky). Participants were instructed to press a key when they spotted the difference, and then describe the difference in a text box. If they did not detect a difference within 60 seconds, the trial timed out. Only trials in which participants correctly identified the changes were included in the analysis. After 30 trials, participants saw each pair of images again, this time side-by-side on the screen. They were asked to identify the focal object(s) in the pictures by typing into a text box. These responses were used as a manipulation check to ensure that participants in both cultures construed focal objects similarly. 

We coded change descriptions to exclude trials in which participants did not identify the change, and checked agreement on focal objects across cultures. We measured how quickly participants identified the difference on trials in which they reported the difference correctly.

#### Taxonomic-Thematic Similarity

@ji2004culture showed that Chinese participants are more likely to match items based on thematic similarity, whereas US participants are more likely to match items based on taxonomic similarity. In this task, participants were presented with triads containing a cue word and two match options. In each test set, one option was a taxonomic match (e.g., monkey - elephant) and the other a thematic match (e.g., monkey - banana). In each filler set, the cue item and the options were broadly similar, thematically and taxonomically, making for a more ambiguous decision (e.g., monkey: elephant, tiger). Participants completed a two-alternative forced choice task in which they chose one match for each cue item. 

The findings of @ji2004culture were replicated in more recent work [@le2021]; we used a subset of testing materials from @le2021, with 15 test triads, 15 filler triads, and 2 attention check questions. The order of the triads was randomized between subjects. We measured taxonomic vs. thematic match selections on each of the test trials. 


#### Semantic Intuition 

@li2018name found cultural differences in semantic intuitions about ambiguous referents in Chinese and US participants. Specifically, Chinese participants were more likely to determine the referent of a name based on the description of the speaker (the descriptivist view) whereas US participants were more likely to determine the referent based on the original usage (the causal-historical view). In the study, participants read five separate stories and judged the correctness of statements referring to a character after each story. Two comprehension check questions were included for each story. We followed the original procedure closely and used the same materials. We measured participants’ semantic intuition as their judgment on the correctness of statements referring to the critical characters. 



