
```{r reliability, fig.cap="Spearman-Brown adjusted reliabilities for tasks with four or more trials. Point shape shows experiment number. Error bars show 95\\% confidence intervals."}
rl <- readRDS(here("cached_results/ea/reliability.RDS"))
plot_rl(rl)
```


One question motivating our work was whether the individual tasks we used were reliable enough – had low enough measurement error – to be used for further investigation of individual differences. The gold standard for evaluating whether a task yields stable within-person measurements is test-retest reliability (simply because test-retest gives a direct estimate of stability over time), but this method was outside the scope of our study. Instead, we used a split-half approach, asking whether participants’ answers on individual questions relate to one another. Specifically, we used a permutation-based split half approach [@parsons2021splithalf] in which we made 5000 random splits of items into two simulated “halves” and then computed the within-person correlation between scores on these two halves, averaging across simulated runs. To estimate the reliability of the full-length instrument, we used the Spearman-Brown “prophecy” formula. 

Since the split-half approach is only suitable for tasks with multiple trials, we removed tasks with fewer than four trials from the analysis. For tasks with more than one condition, we focused on the condition that was predicted to show cultural differences (i.e., the Illusion context in the Ebbinghaus Illusion; situational factors in Adult Causal Attribution; background change scenes in Change Detection). 

```{r}
us_rl <- rl %>% 
  filter(type == "by_culture") %>% 
  filter(culture == "US") %>% 
  select(spearmanbrown, exp, task_name, culture) %>% 
  rename(us = spearmanbrown)

cn_rl <- rl %>% 
  filter(type == "by_culture") %>% 
  filter(culture == "CN") %>% 
  select(spearmanbrown, exp, task_name, culture) %>% 
  rename(cn = spearmanbrown)

cn_us_rl_diff <- cn_rl %>% 
  left_join(us_rl %>% select(-culture), by = c("task_name", "exp")) %>% 
  mutate(us_cn_diff = us-cn)
  
  
```

Figure \@ref(fig:reliability) shows the corrected split-half reliabilities for all tasks in both of our experiments. Overall, the reliabilities were acceptable (all Spearman-Brown Correlations > 0.6). We further investigated whether there was cultural variation in the reliability of tasks. For most tasks, the reliabilities were relatively similar (within 0.1 of one another), but there were three tasks where reliability was lower for US participants than Chinese participants: Change Detection (US - CN = `r filter(cn_us_rl_diff, task_name == "CD")$us_cn_diff`),  Adult Causal Attribution (US - CN = `r filter(cn_us_rl_diff, task_name == "CA" & exp == "exp2")$us_cn_diff`), Free Description in Experiment 1 (US - CN = `r filter(cn_us_rl_diff, task_name == "FD" & exp == "exp1")$us_cn_diff`).
